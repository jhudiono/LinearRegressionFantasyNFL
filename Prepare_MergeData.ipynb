{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import re\n",
    "\n",
    "NAN = float('nan')\n",
    "INPUT_PATH = \"data/1/{}.csv\"\n",
    "OUTPUT_PATH = \"data/2/{}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ingest player stats, Injury, and Division CSVs.\n",
    "2. Add next_fp column to player stats.\n",
    "3. Discard rows for which next_fp can't be determined. \n",
    "4. Merge Division and FFToday datasets (add division column to player info). \n",
    "5. Transform division column to 4x4 matrix. \n",
    "6. Add score column for Injury data.\n",
    "7. Merge player and injury datasets (player name, week, season, injury, status, score).\n",
    "8. Write combined datasets to output path. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import player data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_df_from_files(files):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # get rid of 'Unnamed: 0' column\n",
    "        if 'Unnamed: 0' in df.columns:\n",
    "            df.drop(columns='Unnamed: 0', inplace=True)\n",
    "        \n",
    "        # group chronologically by player\n",
    "        df.sort_values(['name', 'season', 'week'], inplace=True)\n",
    "    \n",
    "        # remove players that have only 1 row, we can't use these for anything\n",
    "        len_before = len(df)\n",
    "        df = df[df.groupby('name').name.transform(len) > 1]\n",
    "        len_lost = len_before - len(df)\n",
    "        print(file, \":\", len_before, \"rows, {0:.0%}\".format(len_lost/len_before), \"unusable\")\n",
    "    \n",
    "        # add column for next week's points\n",
    "        df['next_fp'] = np.where(df['name'] == df['name'].shift(-1), df['fp'].shift(-1), NAN)\n",
    "        df = df.dropna(subset = ['next_fp'])\n",
    "        \n",
    "        # Make sure number of columns is consistent (TE don't have rush data)\n",
    "        if 'rush_att' not in df.columns:\n",
    "            df['rush_att'] = NAN\n",
    "        if 'rush_yd' not in df.columns:\n",
    "            df['rush_yd'] = NAN\n",
    "        if 'rush_td' not in df.columns:\n",
    "            df['rush_td'] = NAN\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: team name from abbr is a mess\n",
    "\n",
    "def get_full_team_name(abbr):\n",
    "    return div_df[div_df['abbr'] == abbr]['team'].get_values()[0]\n",
    "\n",
    "def merge_divisions(player_df):\n",
    "    # Add division column\n",
    "    player_df = player_df.join(div_df[['div', 'abbr']].set_index('abbr'), on='team').reset_index()\n",
    "        \n",
    "    # Transform division column into dummy matrix\n",
    "    dummy_df = patsy.dmatrix('div', data=player_df, return_type='dataframe')\n",
    "    player_df = player_df.join(dummy_df)\n",
    "    \n",
    "    # Translate team abbreviation to the full name\n",
    "    player_df['team'] = player_df['team'].apply(get_full_team_name)\n",
    "\n",
    "    player_df.rename(index=str, columns={\n",
    "        \"div[T.AFC N]\": \"afc_n\",\n",
    "        \"div[T.AFC W]\": \"afc_w\",\n",
    "        \"div[T.AFC S]\": \"afc_s\",\n",
    "        \"div[T.NFC N]\": \"nfc_n\",\n",
    "        \"div[T.NFC W]\": \"nfc_w\",\n",
    "        \"div[T.NFC S]\": \"nfc_s\",\n",
    "        \"div[T.NFC E]\": \"nfc_e\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    player_df.drop(columns=['div', 'Intercept', 'index'], inplace=True)\n",
    "    \n",
    "    return player_df\n",
    "\n",
    "def merge_weather_data(player_df):\n",
    "    weather_cols = ['season','week','team','temperature','wind','precipitation']\n",
    "    player_df = pd.merge(player_df,\n",
    "                         games_df[weather_cols],on=['team','season','week'],how='outer')\n",
    "    return player_df\n",
    "\n",
    "def merge_injury_data(player_df):\n",
    "    # add status_code by joining player and injury on week, season, player\n",
    "    player_df = pd.merge(player_df,\n",
    "                         injury_df[['status_code', 'season', 'week', 'name']],\n",
    "                         on=['name', 'season', 'week'],\n",
    "                         how='outer')\n",
    "    # if status code is NaN, then they were not injured\n",
    "    player_df['status_code'] = player_df['status_code'].fillna(0)\n",
    "    return player_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run everything... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/1/fftoday_2016-2017_pos20.csv : 1700 rows, 2% unusable\n",
      "data/1/fftoday_2014-2015_pos20.csv : 1700 rows, 1% unusable\n",
      "data/1/fftoday_2014-2015_pos30.csv : 1700 rows, 2% unusable\n",
      "data/1/fftoday_2016-2017_pos30.csv : 1700 rows, 2% unusable\n",
      "data/1/fftoday_2016-2017_pos40.csv : 1700 rows, 1% unusable\n",
      "data/1/fftoday_2014-2015_pos40.csv : 1695 rows, 1% unusable\n"
     ]
    }
   ],
   "source": [
    "# Player files\n",
    "RB_files = glob(INPUT_PATH.format(\"fftoday*_pos20\"))\n",
    "WR_files = glob(INPUT_PATH.format(\"fftoday*_pos30\"))\n",
    "TE_files = glob(INPUT_PATH.format(\"fftoday*_pos40\"))\n",
    "assert len(RB_files) > 0, \"where are my files??? path = \"\n",
    "assert len(WR_files) > 0, \"where are my files??? path = \"\n",
    "assert len(TE_files) > 0, \"where are my files??? path = \"\n",
    "\n",
    "RB_df = player_df_from_files(RB_files)\n",
    "WR_df = player_df_from_files(WR_files)\n",
    "TE_df = player_df_from_files(TE_files)\n",
    "assert len(RB_df) > 500, \"RB too small\"\n",
    "assert len(WR_df) > 500, \"WR too small\"\n",
    "assert len(TE_df) > 500, \"TE too small\"\n",
    "\n",
    "# Injury data -- injury_df\n",
    "%run ./Prepare_InjuryData.ipynb\n",
    "assert len(injury_df) > 0, \"where is my injury data???\"\n",
    "\n",
    "# Games data -- games_df\n",
    "%run ./Prepare_GamesData.ipynb\n",
    "assert len(games_df) > 0, \"where is my games/weather data???\"\n",
    "\n",
    "# Division data -- div_df\n",
    "div_df = pd.read_csv('data/team_divisions.csv')\n",
    "assert len(div_df) > 0, \"where is my divisions data???\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>team</th>\n",
       "      <th>rush_att</th>\n",
       "      <th>rush_yd</th>\n",
       "      <th>rush_td</th>\n",
       "      <th>rec_target</th>\n",
       "      <th>rec_rec</th>\n",
       "      <th>rec_yd</th>\n",
       "      <th>rec_td</th>\n",
       "      <th>fp</th>\n",
       "      <th>...</th>\n",
       "      <th>afc_s</th>\n",
       "      <th>afc_w</th>\n",
       "      <th>nfc_e</th>\n",
       "      <th>nfc_n</th>\n",
       "      <th>nfc_s</th>\n",
       "      <th>nfc_w</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>status_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron Jones</td>\n",
       "      <td>Packers</td>\n",
       "      <td>13.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Jones</td>\n",
       "      <td>Packers</td>\n",
       "      <td>19.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Jones</td>\n",
       "      <td>Packers</td>\n",
       "      <td>13.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DOME</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ty Montgomery</td>\n",
       "      <td>Packers</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DOME</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Jones</td>\n",
       "      <td>Packers</td>\n",
       "      <td>17.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name     team  rush_att  rush_yd  rush_td  rec_target  rec_rec  \\\n",
       "0    Aaron Jones  Packers      13.0     49.0      1.0         0.0      0.0   \n",
       "1    Aaron Jones  Packers      19.0    125.0      1.0         1.0      1.0   \n",
       "2    Aaron Jones  Packers      13.0     41.0      0.0         4.0      1.0   \n",
       "3  Ty Montgomery  Packers      10.0     28.0      0.0         3.0      1.0   \n",
       "4    Aaron Jones  Packers      17.0    131.0      1.0         5.0      3.0   \n",
       "\n",
       "   rec_yd  rec_td    fp     ...       afc_s  afc_w  nfc_e  nfc_n  nfc_s  \\\n",
       "0     0.0     0.0  10.9     ...         0.0    0.0    0.0    1.0    0.0   \n",
       "1     9.0     0.0  19.4     ...         0.0    0.0    0.0    1.0    0.0   \n",
       "2     1.0     0.0   4.2     ...         0.0    0.0    0.0    1.0    0.0   \n",
       "3     3.0     0.0   3.1     ...         0.0    0.0    0.0    1.0    0.0   \n",
       "4     7.0     0.0  19.8     ...         0.0    0.0    0.0    1.0    0.0   \n",
       "\n",
       "   nfc_w  temperature  wind  precipitation  status_code  \n",
       "0    0.0           64     4            0.0          0.0  \n",
       "1    0.0           88     2            0.0          0.0  \n",
       "2    0.0         DOME     0            0.0          0.0  \n",
       "3    0.0         DOME     0            0.0          1.0  \n",
       "4    0.0           51     5            0.0          0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RB = RB_df.copy(deep=True)\n",
    "WR = WR_df.copy(deep=True)\n",
    "TE = TE_df.copy(deep=True)\n",
    "dfs = []\n",
    "\n",
    "# make mega DF from player, weather, division, and injury data\n",
    "for tup in [(RB, \"RB_2014-2017\"), \n",
    "            (WR, \"WR_2014-2017\"),\n",
    "            (TE, \"TE_2014-2017\")]:\n",
    "    player_df = tup[0]\n",
    "    \n",
    "    player_df = merge_divisions(player_df)\n",
    "    player_df = merge_weather_data(player_df)\n",
    "    player_df = merge_injury_data(player_df)\n",
    "    \n",
    "    # Drop extra columns, NaN\n",
    "    player_df.drop(columns=['g', 'fpg'], inplace=True)\n",
    "    player_df.dropna(subset=['fp', 'next_fp'], inplace=True)\n",
    "    \n",
    "    dfs.append(player_df)\n",
    "    \n",
    "    # write to csv\n",
    "    player_df.to_csv(OUTPUT_PATH.format(tup[1]))\n",
    "\n",
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1771    2014\n",
       "1772    2015\n",
       "1773    2015\n",
       "1774    2015\n",
       "1775    2015\n",
       "1776    2015\n",
       "1777    2015\n",
       "1778    2015\n",
       "1779    2015\n",
       "1780    2015\n",
       "1781    2015\n",
       "1782    2015\n",
       "1783    2015\n",
       "1784    2015\n",
       "1785    2015\n",
       "1786    2015\n",
       "1787    2015\n",
       "1788    2015\n",
       "1789    2015\n",
       "1790    2015\n",
       "1791    2015\n",
       "1792    2015\n",
       "1793    2015\n",
       "1794    2014\n",
       "1795    2014\n",
       "1796    2014\n",
       "1797    2014\n",
       "1798    2014\n",
       "1799    2014\n",
       "1800    2014\n",
       "        ... \n",
       "3268    2015\n",
       "3269    2015\n",
       "3270    2015\n",
       "3271    2015\n",
       "3272    2014\n",
       "3273    2014\n",
       "3274    2014\n",
       "3275    2014\n",
       "3276    2015\n",
       "3277    2015\n",
       "3278    2015\n",
       "3279    2015\n",
       "3280    2015\n",
       "3281    2015\n",
       "3282    2015\n",
       "3283    2015\n",
       "3284    2015\n",
       "3285    2015\n",
       "3286    2015\n",
       "3287    2015\n",
       "3288    2015\n",
       "3289    2015\n",
       "3290    2014\n",
       "3291    2014\n",
       "3292    2014\n",
       "3293    2014\n",
       "3294    2015\n",
       "3295    2014\n",
       "3296    2014\n",
       "3297    2014\n",
       "Name: season, Length: 1527, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = dfs[0]\n",
    "test[test['precipitation'].isnull()]['season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
