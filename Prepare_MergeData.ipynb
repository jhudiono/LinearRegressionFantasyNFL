{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import re\n",
    "\n",
    "NAN = float('nan')\n",
    "INPUT_PATH = \"data/1/{}.csv\"\n",
    "OUTPUT_PATH = \"data/2/{}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ingest player stats, Injury, and Division CSVs.\n",
    "2. Add next_fp column to player stats.\n",
    "3. Discard rows for which next_fp can't be determined. \n",
    "4. Merge Division and FFToday datasets (add division column to player info). \n",
    "5. Transform division column to 4x4 matrix. \n",
    "6. Add score column for Injury data.\n",
    "7. Merge player and injury datasets (player name, week, season, injury, status, score).\n",
    "8. Write combined datasets to output path. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import player data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_df_from_files(files):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # get rid of 'Unnamed: 0' column\n",
    "        if 'Unnamed: 0' in df.columns:\n",
    "            df.drop(columns='Unnamed: 0', inplace=True)\n",
    "        \n",
    "        # group chronologically by player\n",
    "        df.sort_values(['name', 'season', 'week'], inplace=True)\n",
    "    \n",
    "        # remove players that have only 1 row, we can't use these for anything\n",
    "        len_before = len(df)\n",
    "        df = df[df.groupby('name').name.transform(len) > 1]\n",
    "        len_lost = len_before - len(df)\n",
    "        print(file, \":\", len_before, \"rows, {0:.0%}\".format(len_lost/len_before), \"unusable\")\n",
    "    \n",
    "        # add column for next week's points\n",
    "        df['next_fp'] = np.where(df['name'] == df['name'].shift(-1), df['fp'].shift(-1), NAN)\n",
    "        df = df.dropna(subset = ['next_fp'])\n",
    "        \n",
    "        # Make sure number of columns is consistent (TE don't have rush data)\n",
    "        if 'rush_att' not in df.columns:\n",
    "            df['rush_att'] = NAN\n",
    "        if 'rush_yd' not in df.columns:\n",
    "            df['rush_yd'] = NAN\n",
    "        if 'rush_td' not in df.columns:\n",
    "            df['rush_td'] = NAN\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: team name from abbr is a mess\n",
    "\n",
    "def get_full_team_name(abbr):\n",
    "    return div_df[div_df['abbr'] == abbr]['team'].get_values()[0]\n",
    "\n",
    "def merge_divisions(player_df):\n",
    "    # Add division column\n",
    "    player_df = player_df.join(div_df[['div', 'abbr']].set_index('abbr'), on='team').reset_index()\n",
    "        \n",
    "    # Transform division column into dummy matrix\n",
    "    dummy_df = patsy.dmatrix('div', data=player_df, return_type='dataframe')\n",
    "    player_df = player_df.join(dummy_df)\n",
    "    \n",
    "    # Translate team abbreviation to the full name\n",
    "    player_df['team'] = player_df['team'].apply(get_full_team_name)\n",
    "\n",
    "    player_df.rename(index=str, columns={\n",
    "        \"div[T.AFC N]\": \"afc_n\",\n",
    "        \"div[T.AFC W]\": \"afc_w\",\n",
    "        \"div[T.AFC S]\": \"afc_s\",\n",
    "        \"div[T.NFC N]\": \"nfc_n\",\n",
    "        \"div[T.NFC W]\": \"nfc_w\",\n",
    "        \"div[T.NFC S]\": \"nfc_s\",\n",
    "        \"div[T.NFC E]\": \"nfc_e\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    player_df.drop(columns=['div', 'Intercept', 'index'], inplace=True)\n",
    "    \n",
    "    return player_df\n",
    "\n",
    "def merge_weather_data(player_df):\n",
    "    weather_cols = ['season','week','team','temperature','wind','precipitation','dome']\n",
    "    player_df = pd.merge(player_df,\n",
    "                         games_df[weather_cols],on=['team','season','week'],how='outer')\n",
    "    return player_df\n",
    "\n",
    "def merge_injury_data(player_df):\n",
    "    # add status_code by joining player and injury on week, season, player\n",
    "    player_df = pd.merge(player_df,\n",
    "                         injury_df[['status_code', 'season', 'week', 'name']],\n",
    "                         on=['name', 'season', 'week'],\n",
    "                         how='outer')\n",
    "    # if status code is NaN, then they were not injured\n",
    "    player_df['status_code'] = player_df['status_code'].fillna(0)\n",
    "    return player_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run everything... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/1/fftoday_2016-2017_pos20.csv : 1700 rows, 2% unusable\n",
      "data/1/fftoday_2014-2015_pos20.csv : 1700 rows, 1% unusable\n",
      "data/1/fftoday_2014-2015_pos30.csv : 1700 rows, 2% unusable\n",
      "data/1/fftoday_2016-2017_pos30.csv : 1700 rows, 2% unusable\n",
      "data/1/fftoday_2016-2017_pos40.csv : 1700 rows, 1% unusable\n",
      "data/1/fftoday_2014-2015_pos40.csv : 1695 rows, 1% unusable\n",
      "Backfilling 6 out of 2200\n",
      "Writing file to  data/2/games_dome_2014-2017.csv\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Player files\n",
    "RB_files = glob(INPUT_PATH.format(\"fftoday*_pos20\"))\n",
    "WR_files = glob(INPUT_PATH.format(\"fftoday*_pos30\"))\n",
    "TE_files = glob(INPUT_PATH.format(\"fftoday*_pos40\"))\n",
    "assert len(RB_files) > 0, \"where are my files??? path = \"\n",
    "assert len(WR_files) > 0, \"where are my files??? path = \"\n",
    "assert len(TE_files) > 0, \"where are my files??? path = \"\n",
    "\n",
    "RB_df = player_df_from_files(RB_files)\n",
    "WR_df = player_df_from_files(WR_files)\n",
    "TE_df = player_df_from_files(TE_files)\n",
    "assert len(RB_df) > 500, \"RB too small\"\n",
    "assert len(WR_df) > 500, \"WR too small\"\n",
    "assert len(TE_df) > 500, \"TE too small\"\n",
    "\n",
    "# Injury data -- injury_df\n",
    "%run ./Prepare_InjuryData.ipynb\n",
    "assert len(injury_df) > 0, \"where is my injury data???\"\n",
    "\n",
    "# Games data -- games_df\n",
    "%run ./Prepare_GamesData.ipynb\n",
    "assert len(games_df) > 0, \"where is my games/weather data???\"\n",
    "\n",
    "# Division data -- div_df\n",
    "div_df = pd.read_csv('data/team_divisions.csv')\n",
    "assert len(div_df) > 0, \"where is my divisions data???\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to path data/2/RB_2014-2017.csv\n",
      "Writing to path data/2/WR_2014-2017.csv\n",
      "Writing to path data/2/TE_2014-2017.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>team</th>\n",
       "      <th>rush_att</th>\n",
       "      <th>rush_yd</th>\n",
       "      <th>rush_td</th>\n",
       "      <th>rec_target</th>\n",
       "      <th>rec_rec</th>\n",
       "      <th>rec_yd</th>\n",
       "      <th>rec_td</th>\n",
       "      <th>fp</th>\n",
       "      <th>...</th>\n",
       "      <th>afc_w</th>\n",
       "      <th>nfc_e</th>\n",
       "      <th>nfc_n</th>\n",
       "      <th>nfc_s</th>\n",
       "      <th>nfc_w</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>dome</th>\n",
       "      <th>status_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron Jones</td>\n",
       "      <td>Packers</td>\n",
       "      <td>13.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Jones</td>\n",
       "      <td>Packers</td>\n",
       "      <td>19.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Jones</td>\n",
       "      <td>Packers</td>\n",
       "      <td>13.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ty Montgomery</td>\n",
       "      <td>Packers</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Jones</td>\n",
       "      <td>Packers</td>\n",
       "      <td>17.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name     team  rush_att  rush_yd  rush_td  rec_target  rec_rec  \\\n",
       "0    Aaron Jones  Packers      13.0     49.0      1.0         0.0      0.0   \n",
       "1    Aaron Jones  Packers      19.0    125.0      1.0         1.0      1.0   \n",
       "2    Aaron Jones  Packers      13.0     41.0      0.0         4.0      1.0   \n",
       "3  Ty Montgomery  Packers      10.0     28.0      0.0         3.0      1.0   \n",
       "4    Aaron Jones  Packers      17.0    131.0      1.0         5.0      3.0   \n",
       "\n",
       "   rec_yd  rec_td    fp     ...       afc_w  nfc_e  nfc_n  nfc_s  nfc_w  \\\n",
       "0     0.0     0.0  10.9     ...         0.0    0.0    1.0    0.0    0.0   \n",
       "1     9.0     0.0  19.4     ...         0.0    0.0    1.0    0.0    0.0   \n",
       "2     1.0     0.0   4.2     ...         0.0    0.0    1.0    0.0    0.0   \n",
       "3     3.0     0.0   3.1     ...         0.0    0.0    1.0    0.0    0.0   \n",
       "4     7.0     0.0  19.8     ...         0.0    0.0    1.0    0.0    0.0   \n",
       "\n",
       "   temperature  wind  precipitation  dome  status_code  \n",
       "0           88     2            0.0   0.0          0.0  \n",
       "1           70     0            0.0   1.0          0.0  \n",
       "2           51     5            0.0   0.0          0.0  \n",
       "3           51     5            0.0   0.0          0.0  \n",
       "4           28     9            0.0   0.0          0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RB = RB_df.copy(deep=True)\n",
    "WR = WR_df.copy(deep=True)\n",
    "TE = TE_df.copy(deep=True)\n",
    "dfs = []\n",
    "\n",
    "# make mega DF from player, weather, division, and injury data\n",
    "for tup in [(RB, \"RB_2014-2017\"), \n",
    "            (WR, \"WR_2014-2017\"),\n",
    "            (TE, \"TE_2014-2017\")]:\n",
    "    player_df = tup[0]\n",
    "    \n",
    "    player_df = merge_divisions(player_df)\n",
    "    player_df = merge_weather_data(player_df)\n",
    "    player_df = merge_injury_data(player_df)\n",
    "    \n",
    "    # Drop extra columns, fp == NaN, next_fp == NaN, backfill/ffill other NaNs\n",
    "    player_df.drop(columns=['g', 'fpg'], inplace=True)\n",
    "    player_df.dropna(subset=['fp', 'next_fp'], inplace=True)\n",
    "    player_df.fillna(method='bfill', inplace=True)\n",
    "    player_df.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    dfs.append(player_df)\n",
    "    \n",
    "    # write to csv\n",
    "    print(\"Writing to path\", OUTPUT_PATH.format(tup[1]))\n",
    "    player_df.to_csv(OUTPUT_PATH.format(tup[1]))\n",
    "\n",
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = dfs[0]\n",
    "nan_df = test[test['precipitation'].isnull()][['season', 'week', 'team', 'precipitation', 'wind', 'temperature']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some NAN values for weather. Might have to do some manual massaging, but these are only a few rows. Probably ok to just drop. \n",
    "* 2014, 4 Jaguars vs Chargers was partly cloudy, probably no precipitation\n",
    "* 2014, 4 Dolphins vs Raiders was partly cloudy but no wind information\n",
    "* 2014, 10 Cowboys vs Jaguars was 70% rain \n",
    "* 2014, 8 Falcons vs Lions was cloudy but no wind information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in dfs:\n",
    "    print(len(d[d['precipitation'].isnull()]), \"unknown precipitation\")\n",
    "    print(len(d[d['temperature'].isnull()]), \"unknown temperature\")\n",
    "    print(len(d[d['wind'].isnull()]), \"unknown wind\")\n",
    "    print(d.isnull().sum().sum(), \"total nan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
